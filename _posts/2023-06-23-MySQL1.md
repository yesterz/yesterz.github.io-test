---
title:  "ch1-MySQL的逻辑架构"
layout: post
toc: true
---

MySQL 可以分为 Server 层和存储引擎层两部分
<br/>
### ch1 MySQL架构

### MySQL 的逻辑架构

MySQL 可以分为 Server 层和存储引擎层两部分

- **Server 层**
    - 连接器 → 管理链接，权限验证
    - 查询缓存 → 8.0 后整块功能就删掉了
    - 分析器 → 词法分析，语法分析
    - 优化器 → 执行计划生成，索引选择
    - 执行器 → 与存储引擎交互，返回结果
- **存储引擎层** 服务器通过 API 与存储引擎进行通信
    - InnoDB (default)
    - MyISAM
    - Memory

---

# 并发控制

> 数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。
> 

在处理并发读或者写的时候，可以通过实现一个由两种类型的锁组成的锁系统来解决问题。

通常称之为**共享锁（shared lock）**和**排他锁（exclusive lock）**，也叫读锁（read lock）和写锁（write lock）。

**具体描述读写锁的概念：**

1. 读锁是共享的，或者说是互相不阻塞的
  
    多个客户在同一时刻可以同时读取同一个资源，而互不干扰。
    
2. 写锁是排他的，一个写锁会阻塞其他的写锁和读锁
  
    写锁这种安全策略，才可以确保在给定的时间里，只有一个用户能执行写入，并防止其他用户读取正在写入的同一资源。
    

提高共享资源并发性：尽量只锁定需要修改的部分数据，而不是所有资源。

更理想的方式是，只对会修改的数据片进行精确的锁定。锁定的数据量越少，则系统的并发程度越高，只要互相之间不发生冲突就行。

锁的各种操作也会增加系统开销：获得锁、检查锁是否已经解除、释放锁等

在锁的开销和数据的安全性之间平衡一下的锁的策略就是一般都是在表上施加行级锁（row-level lock）

**具体描述表锁的概念（table lock）:**

1. 表锁是开销最小的策略，是MySQL中最基本的锁策略
2. 锁定整张表，一个用户在对表进行写操作（插入、删除、更新等）前，都要先获得**写锁**，这阻塞了其他用户对这张表的读写操作。
3. 没有写锁时，其他读的用户才能获得读锁，读锁之间时不互相阻塞的。
4. 写锁比读锁有更高的优先级，因此写锁请求可能会被插入到锁队列中读锁的前面，反之不可以。

**具体描述行级锁的概念（row lock）：**

1. 行级锁可以最大程度地支持并发处理，同时带来了最大的锁开销。
2. 行级锁只在存储引擎层实现，MyISAM 引擎就不支持行锁。
3. **在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。事务持有的记录的锁都是在 commit 的时候才释放。**

全局锁：

全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 `Flush tables with read lock (FTWRL)`

当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都select出来存成文本。

# 事务

1. ~~基础概念介绍~~
2. ~~隔离级别~~
3. ~~死锁~~
4. ~~事务日志~~
5. ~~MySQL 中的事务~~
- **基础概念介绍**
1. 事务就是一组原子性的 SQL 查询，或者说一个独立的工作单元。事务内的语句要么全部执行成功，要么全部执行失败。
2. 事务的 AICD 特性
    1. 原子性 atomicity
      
        一个事务就被视为一个不可分割的最小工作单元，其所有操作要么全部提交成功，要么全部失败回滚。不能只执行其中的一部分。
        
    2. 一致性 consistency
      
        数据库总是从一个一致性的状态转换到另外一个一致性的状态。
        
    3. 隔离性 isolation
      
        通常来说，一个事务所做的修改在最终提交以前，对其他事务时不可见的。（具体隔离级别来讨论）
        
    4. 持久性 durability
      
        事务一旦提交，则其所做的修改就会永久保存到数据库中。
    
3. 在 MySQL 中，事务支持是在引擎层实现的。MySQL 原生的 MyISAM 引擎就不支持事务。
- **隔离级别 isolation level**
  
    当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，所以就有了隔离级别的概念。
    
    | isolation level | 脏读可能性 | 不可重复读可能性 | 幻读可能性 | 加锁读 |
    | --- | --- | --- | --- | --- |
    | READ UNCOMMITTED | Yes | Yes | Yes | No |
    | READ COMMITTED | No | Yes | Yes | No |
    | REPEATABLE READ | No | No | Yes | No |
    | SERIALIZABLE | No | No | No | Yes |
1. READ UNCOMMITTED （未提交读）
  
    读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
    
    事务中的修改，即使没有提交，对其他事务也都是可见的。事务可以读取到未提交的数据，称之为**脏读（Dirty Read）。一般不用此隔离级别**
    
2. READ COMMITTED （提交读）
  
    读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
    
    大多数 DBMS 的默认级别（如 Oracle）。**但 MySQL 不是。**此级别可以满足 AICD 中的隔离性，一个事务从开始到提交之前，所做的任何修改对其他事务都是不可见的。有时候这个级别也叫做不可重复读（nonrepeatable read），因为两次执行同样的查询，可能会得到不一样的结果。
    
3. REPEATABLE READ （可重复读）
  
    可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
    
    解决了脏读的问题。该级别保证了**在同一个事务多次读取同样的记录的结果是一致的，**换句话说就是事务在执行期间看到的数据前后必须是一致的。但理论上无法解决另外一个幻读（phantom read）的问题。所谓幻读，指的是当某个事务在读取某个范围内的记录时，会产生幻行（phantom row）。InnoDB 和 XtraDB 存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）解决了幻读的问题。
    
    **可重复读时 MySQL 的默认事务隔离级别。**
    
4. SERIALIZABLE （可串行化）
  
    串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。
    
    最高的隔离执行。它强制事务串行执行，避免了幻读问题。它会在读取的每一行数据上都加锁，可能会导致超时和锁竞争的问题。
    
    实际开发很少用，非常需要确保数据的一致性时且可以接受没有并发的情况，才考虑。
    

在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。

```sql
show variables like 'transaction_isolation';
```

- **死锁**

死锁是指两个或者**多个事务在同一资源上相互占用，并请求锁定对方占用的资源**，从而导致恶性循环的现象。

1. InnoDB 存储引擎，能检测到死锁的循环依赖，并立即返回一个错误。
2. InnoDB 处理死锁的办法是，将持有最少行级排他锁的事务进行回滚（这时相对简单的死锁回滚算法）
3. 死锁产生有双重原因：
    1. 有些是因为真正的数据冲突
    2. 有些则是完全由于存储引擎的实现方式导致的
4. 如何处理死锁，大多数情况下只需要重新执行因死锁回滚的事务即可
- **事务日志 redo log**
1. 事务日志采用的是追加的方式，写日志的操作是磁盘上一小块区域的顺序 I/O
2. 事务日志持久化以后，内存中被修改的数据在后台可以慢慢地刷回到磁盘——预写式日志（Write-Ahead Logging），修改数据需要写两次磁盘
- **MySQL 中的事务**
1. 自动提交（AUTOCOMMIT）
    1. MySQL 默认采用的是自动提交模式，如果不是显式的开始一个事务，则每个查询都被当做一个事务执行提交操作。
    2. `show variables like ‘autocommit’;` `set autocommit = 1;`
    3. 对于非事务型的表，如 MyISAM 或内存表，不会有任何影响。
2. 在事务中混合使用存储引擎
    1. 不可靠！
    2. 在事务中混合使用了事务型和非事务型的表（InnoDB 和 MyISAM 表），如果需要回滚则会发生警告，某些非事务型的表上的变更不能被回滚
3. 隐式和显式锁定
    1. InnoDB 采用的时两阶段锁定协议（two-phase locking protocol）
    2. 在事务执行过程中，随时都可以执行锁定，锁只有在执行 commit 或者 rollback 的时候才会释放，并且所有的锁是在同一时刻被释放。这里描述的锁定都是隐式锁定，InnoDB 会根据隔离级别在需要的时候自动加锁
    3. InnoDB 的显示锁定
        1. `SELECT … LOCK IN SHARE MODE`
        2. `SELECT … FOR UPDATE`

# 多版本并发控制 MVCC

可以认为 MVCC 是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低。实现了非阻塞的读操作，写操作也只锁定必要的行。

MVCC 的实现，是通过**保存数据在某个时间点的快照**来实现的。不管需要执行多长时间，每个事物看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。

通过 InnoDB 简化版行为说明 MVCC 是如何工作的：

InnoDB 的 MVCC，是通过在每行后面保存两个隐藏的列来实现的。一个保存了行的创建时间，一个保存行的过期时间（或删除时间）。当然存储的并不是实际的时间值，而是系统版本号（system version number）。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。

在 REPEATABLE READ 隔离级别下，MVCC 具体是如何操作的？

**SELECT**

InnoDB 会根据以下两个条件检查每行记录：

1. InnoDB 只查找版本早于当前事务版本的数据行（也就是，行的系统版本号小于或等于事务的系统版本号），这样可以确保事务读取的行，要么是在事务开始前已经存在，要么是事务自身插入或修改过的。
2. 行的删除版本要么未定义，要么大于当前事务版本号。这样可以确保事务读取到的行，在事务开始之前未被删除。

只有符合上述两个条件的记录，才能返回作为查询结果。

**INSERT**

InnoDB 为新插入的每一行保存当前系统版本号作为行版本号。

**DELETE**

InnoDB 为删除的每一行保存当前系统版本号作为行删除标识。

**UPDATE**

InnoDB 为插入一行新纪录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。

保存这两个额外系统版本号，使大多数读操作都可以不用加锁。

MVCC 只在 REPEATABLE READ 和 READ COMMITTED 两个隔离级别下工作。

READ UNCOMMITTED 总是读取最新的数据行，而不是符合当前事务版本的数据行

SERIALIZABLE 则会对所有读取的行都加锁

# MySQL 的存储引擎

- **InnoDB 存储引擎**

InnoDB 是 MySQL 的默认事务型引擎。被设计用来处理大量短期（short-lived）事务

InnoDB 的数据存储在表空间（tablespace）中，表空间是由 InnoDB 管理的一个黑盒子，由一系列的数据文件组成。

InnoDB 采用 MVCC 来支持高并发，并且实现了四个标准的隔离级别。

默认级别是 REPEATABLE READ（可重复读），并且通过间隙锁策略防止幻读的出现。间隙锁还会对索引中的间隙进行锁定，以防止幻影行的插入。

InnoDB 表是基于聚簇索引建立的。

聚簇索引对主键查询有很高的性能，不过它的二级索引（secondary index，非主键索引）中必须包含主键列

InnoDB 内部做了很多优化。

包括从磁盘读取数据时采用的可预测性预读，能够自动在内存中创建 hash 索引以加速读操作的自适应哈希索引（adaptive hash index），以及能够加速插入操作的插入缓冲区（insert buffer）等

- **MyISAM 存储引擎**

MySQL 5.1 及之前的版本，MyISAM 是默认的存储引擎。提供了大量的特性，包括全文索引、压缩、空间函数（GIS）等，但不支持事务和行级锁，而且有一个毫无疑问的缺陷就是崩溃后无法安全恢复。

存储

MyISAM 会将表存储在两个文件中：数据文件（.MYD）和索引文件（.MYI）。MyISAM 表可以包含动态或者静态（长度固定）行。

MyISAM 特性

1. 加锁于并发
  
    加锁对整张表加锁，而不是针对行。读取时会对需要读到的所有表加共享锁，写入时则对表加排他锁。但是在表有读取查询的同时，也可以往表中插入新的记录（称为并发插入，CONCURRENT INSERT）
    
2. 修复
  
    对于 MyISAM 表，MySQL 可以手工或者自动执行检查和修复操作。`check table mytable;` `repair table mytable;`
    
3. 索引特性
  
    对于 MyISAM 表，即使是 BLOB 和 TEXT 等长字段，也可以基于其前 500 个字符创建索引。也支持全文索引，是基于分词创建的索引。
    
4. 延迟更新索引键（Delayed Key Write）
  
    创建 MyISAM 表的时候，如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立刻将修改的索引的数据写入磁盘，而是会写到内存中的键缓冲区（in-memory key buffer），只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入到磁盘。
    

MyISAM 压缩表

MyISAM 性能

- **Archive 引擎**

Archive 存储引擎只支持 INSERT 和 SELECT 操作。

Archive 引擎会缓存所有的写并利用 zlib 对插入的行进行压缩，所有比 MyISAM 表的磁盘 I/O 更少。但是每次 SELECT 查询都需要执行全表扫描，所以 Archive 表适合日志和数据采集类应用。

Archive 引擎支持行级锁和专用的缓冲区，所以可以实现高并发的插入。

在一个查询开始直到返回表中存在的所有行数之前，Archive 引擎会阻止其他的 SELECT 执行，以实现一致性读。也实现了批量插入在完成之前对读操作时不可见的。

Archive 引擎是一个针对高速插入和压缩做了优化的简单引擎。

- **Blackhole 引擎**

没有实现任何的存储机制，它会丢弃所有插入的数据，不做任何保存。但是服务器会记录 Blackhole 表的日志，所以可以用于复制数据到备库，或者只是简单地记录日志。

- **CSV 引擎**

不支持索引，可以作为一种数据交换地机制，非常有用。

- **Federated 引擎**

Federated 引擎是访问其他 MySQL 服务器地一个代理，它会创建一个到远程 MySQL 服务器地客户端连接，并将查询传输到远程服务器执行，然后提取或者发送需要的数据。

- **Memory 引擎**

快速的访问数据，并且这些数据不会被修改，重启一行丢失也没有关系，使用 Memory 表是非常有用的。至少比 MyISAM 表要快一个数量级。数据都保存在内存中，不需要进行磁盘 I/O，Memory 表结构在重启后会保留，但数据丢失。

支持 Hash 索引。是表级锁，并发写入性能低。

1. 用于查找（lookup）或映射（mapping）表
2. 用于缓存周期性聚合数据（periodically aggregated data）的结果
3. 用于保存数据分析中产生的中间数据
- **Merge 引擎**

MyISAM 引擎的一个变种，Merge 表是由多个 MyISAM 表合并而来的虚拟表。

- **NDB 集群引擎**

MySQL 服务器、NDB 集群存储引擎，以及分布式的、share-nothing 的、容灾的、高可用的 NDB 数据库的组合，被称为 MySQL 集群（MySQL Cluster）

# 选择合适的引擎

大部分情况下，InnoDB 都是正确的选择。

除非需要用到某些 InnoDB 不具备的特性，并且没有其他办法可以替代，否则都应该优先选择 InnoDB 引擎。

考虑因素：事务、备份、崩溃恢复、特有的特性

# 转换表的引擎

1. ALTER TABLE
  
    `alter table mytable engine = InnoDB;`
    
2. 导出与导入
3. 创建与查询（CREATE 和 SELECT）
  
    ```sql
    create table innoda_table like myisam_table;
    alter table innodb_table engine=innodb;
    insert into innodb_table select * from myisam_table;
    
    start transaction;
    insert into innodb_table select * from myisam_table where id between x and y;
    commit;
    ```
